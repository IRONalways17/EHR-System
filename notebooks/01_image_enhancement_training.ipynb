{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad163af9",
   "metadata": {},
   "source": [
    "# Module 2: Medical Image Enhancement Model Training\n",
    "\n",
    "This notebook trains a deep learning model for medical image enhancement using U-Net architecture.\n",
    "\n",
    "## Objectives:\n",
    "- Train U-Net model for image denoising and enhancement\n",
    "- Implement custom loss functions (L1 + Perceptual Loss)\n",
    "- Evaluate model performance with PSNR/SSIM metrics\n",
    "- Save trained model for deployment\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529c0abb",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9102340d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add project root to path\n",
    "project_root = os.path.abspath('..')\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "    sys.path.insert(0, os.path.join(project_root, 'src'))\n",
    "\n",
    "print(f\"Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c3364a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1d492d",
   "metadata": {},
   "source": [
    "## 2. Define U-Net Architecture\n",
    "\n",
    "U-Net is a convolutional neural network designed for medical image segmentation and enhancement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4f155e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(Conv2D -> BatchNorm -> ReLU) * 2\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    \"\"\"U-Net for Medical Image Enhancement\"\"\"\n",
    "    def __init__(self, in_channels=1, out_channels=1, features=[64, 128, 256, 512]):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.ModuleList()\n",
    "        self.decoder = nn.ModuleList()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Encoder (downsampling)\n",
    "        for feature in features:\n",
    "            self.encoder.append(DoubleConv(in_channels, feature))\n",
    "            in_channels = feature\n",
    "        \n",
    "        # Bottleneck\n",
    "        self.bottleneck = DoubleConv(features[-1], features[-1] * 2)\n",
    "        \n",
    "        # Decoder (upsampling)\n",
    "        for feature in reversed(features):\n",
    "            self.decoder.append(\n",
    "                nn.ConvTranspose2d(feature * 2, feature, kernel_size=2, stride=2)\n",
    "            )\n",
    "            self.decoder.append(DoubleConv(feature * 2, feature))\n",
    "        \n",
    "        # Final output layer\n",
    "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        skip_connections = []\n",
    "        \n",
    "        # Encoder\n",
    "        for encode in self.encoder:\n",
    "            x = encode(x)\n",
    "            skip_connections.append(x)\n",
    "            x = self.pool(x)\n",
    "        \n",
    "        # Bottleneck\n",
    "        x = self.bottleneck(x)\n",
    "        skip_connections = skip_connections[::-1]\n",
    "        \n",
    "        # Decoder\n",
    "        for idx in range(0, len(self.decoder), 2):\n",
    "            x = self.decoder[idx](x)\n",
    "            skip_connection = skip_connections[idx // 2]\n",
    "            \n",
    "            # Handle size mismatch\n",
    "            if x.shape != skip_connection.shape:\n",
    "                x = nn.functional.interpolate(x, size=skip_connection.shape[2:])\n",
    "            \n",
    "            concat_skip = torch.cat((skip_connection, x), dim=1)\n",
    "            x = self.decoder[idx + 1](concat_skip)\n",
    "        \n",
    "        return torch.sigmoid(self.final_conv(x))\n",
    "\n",
    "\n",
    "# Test the model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = UNet(in_channels=1, out_channels=1).to(device)\n",
    "test_input = torch.randn(1, 1, 256, 256).to(device)\n",
    "test_output = model(test_input)\n",
    "print(f\"Model input shape: {test_input.shape}\")\n",
    "print(f\"Model output shape: {test_output.shape}\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38848ec9",
   "metadata": {},
   "source": [
    "## 3. Create Dataset and DataLoader\n",
    "\n",
    "Generate synthetic training data with various types of degradation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b84f766",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MedicalImageDataset(Dataset):\n",
    "    \"\"\"Dataset for medical image enhancement training\"\"\"\n",
    "    \n",
    "    def __init__(self, num_samples=1000, image_size=256, noise_level=0.1):\n",
    "        self.num_samples = num_samples\n",
    "        self.image_size = image_size\n",
    "        self.noise_level = noise_level\n",
    "        \n",
    "    def generate_synthetic_image(self):\n",
    "        \"\"\"Generate synthetic medical image\"\"\"\n",
    "        image = np.zeros((self.image_size, self.image_size), dtype=np.float32)\n",
    "        \n",
    "        # Add circular structures (simulating organs/tissues)\n",
    "        num_circles = np.random.randint(3, 8)\n",
    "        for _ in range(num_circles):\n",
    "            center_x = np.random.randint(50, self.image_size - 50)\n",
    "            center_y = np.random.randint(50, self.image_size - 50)\n",
    "            radius = np.random.randint(20, 60)\n",
    "            intensity = np.random.uniform(0.3, 0.9)\n",
    "            cv2.circle(image, (center_x, center_y), radius, intensity, -1)\n",
    "        \n",
    "        # Add ellipses\n",
    "        num_ellipses = np.random.randint(2, 5)\n",
    "        for _ in range(num_ellipses):\n",
    "            center = (np.random.randint(50, self.image_size - 50),\n",
    "                     np.random.randint(50, self.image_size - 50))\n",
    "            axes = (np.random.randint(15, 40), np.random.randint(15, 40))\n",
    "            angle = np.random.randint(0, 180)\n",
    "            intensity = np.random.uniform(0.2, 0.7)\n",
    "            cv2.ellipse(image, center, axes, angle, 0, 360, intensity, -1)\n",
    "        \n",
    "        # Apply Gaussian smoothing (tissue-like texture)\n",
    "        image = cv2.GaussianBlur(image, (15, 15), 3)\n",
    "        \n",
    "        return image\n",
    "    \n",
    "    def add_degradation(self, image):\n",
    "        \"\"\"Add noise and blur to simulate degraded images\"\"\"\n",
    "        degraded = image.copy()\n",
    "        \n",
    "        # Add Gaussian noise\n",
    "        noise = np.random.normal(0, self.noise_level, image.shape).astype(np.float32)\n",
    "        degraded = degraded + noise\n",
    "        \n",
    "        # Add blur\n",
    "        degraded = cv2.GaussianBlur(degraded, (5, 5), 1.5)\n",
    "        \n",
    "        # Clip values\n",
    "        degraded = np.clip(degraded, 0, 1)\n",
    "        \n",
    "        return degraded\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Generate clean image\n",
    "        clean_image = self.generate_synthetic_image()\n",
    "        \n",
    "        # Generate degraded version\n",
    "        degraded_image = self.add_degradation(clean_image)\n",
    "        \n",
    "        # Convert to tensors\n",
    "        clean_tensor = torch.from_numpy(clean_image).unsqueeze(0)  # Add channel dim\n",
    "        degraded_tensor = torch.from_numpy(degraded_image).unsqueeze(0)\n",
    "        \n",
    "        return degraded_tensor, clean_tensor\n",
    "\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = MedicalImageDataset(num_samples=800, image_size=256, noise_level=0.1)\n",
    "val_dataset = MedicalImageDataset(num_samples=200, image_size=256, noise_level=0.1)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Batches per epoch: {len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d8479f",
   "metadata": {},
   "source": [
    "## 4. Visualize Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5059d594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images\n",
    "degraded, clean = next(iter(train_loader))\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "fig.suptitle('Training Data Samples', fontsize=16, fontweight='bold')\n",
    "\n",
    "for i in range(4):\n",
    "    # Degraded images\n",
    "    axes[0, i].imshow(degraded[i, 0].cpu().numpy(), cmap='gray')\n",
    "    axes[0, i].set_title(f'Degraded Image {i+1}')\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # Clean images\n",
    "    axes[1, i].imshow(clean[i, 0].cpu().numpy(), cmap='gray')\n",
    "    axes[1, i].set_title(f'Clean Image {i+1}')\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f907e3d",
   "metadata": {},
   "source": [
    "## 5. Define Loss Functions and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b74f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedLoss(nn.Module):\n",
    "    \"\"\"Combined L1 and MSE loss for better reconstruction\"\"\"\n",
    "    def __init__(self, l1_weight=0.7, mse_weight=0.3):\n",
    "        super().__init__()\n",
    "        self.l1_weight = l1_weight\n",
    "        self.mse_weight = mse_weight\n",
    "        self.l1_loss = nn.L1Loss()\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        l1 = self.l1_loss(pred, target)\n",
    "        mse = self.mse_loss(pred, target)\n",
    "        return self.l1_weight * l1 + self.mse_weight * mse\n",
    "\n",
    "\n",
    "def calculate_metrics(pred, target):\n",
    "    \"\"\"Calculate PSNR and SSIM metrics\"\"\"\n",
    "    pred_np = pred.cpu().detach().numpy()\n",
    "    target_np = target.cpu().detach().numpy()\n",
    "    \n",
    "    psnr_values = []\n",
    "    ssim_values = []\n",
    "    \n",
    "    for i in range(pred_np.shape[0]):\n",
    "        pred_img = pred_np[i, 0]\n",
    "        target_img = target_np[i, 0]\n",
    "        \n",
    "        psnr_val = psnr(target_img, pred_img, data_range=1.0)\n",
    "        ssim_val = ssim(target_img, pred_img, data_range=1.0)\n",
    "        \n",
    "        psnr_values.append(psnr_val)\n",
    "        ssim_values.append(ssim_val)\n",
    "    \n",
    "    return np.mean(psnr_values), np.mean(ssim_values)\n",
    "\n",
    "\n",
    "# Initialize loss function\n",
    "criterion = CombinedLoss(l1_weight=0.7, mse_weight=0.3)\n",
    "print(\"Loss function initialized: Combined L1 (70%) + MSE (30%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b7bccd",
   "metadata": {},
   "source": [
    "## 6. Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c3be43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 0.001\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initialize model, optimizer, scheduler\n",
    "model = UNet(in_channels=1, out_channels=1).to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "# Create model directory\n",
    "model_dir = Path('../models/image_enhancement')\n",
    "model_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Training configuration:\")\n",
    "print(f\"  Device: {DEVICE}\")\n",
    "print(f\"  Epochs: {EPOCHS}\")\n",
    "print(f\"  Learning Rate: {LEARNING_RATE}\")\n",
    "print(f\"  Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"  Model save path: {model_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66689f95",
   "metadata": {},
   "source": [
    "## 7. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1f2c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_psnr = 0.0\n",
    "    running_ssim = 0.0\n",
    "    \n",
    "    progress_bar = tqdm(dataloader, desc='Training')\n",
    "    for degraded, clean in progress_bar:\n",
    "        degraded = degraded.to(device)\n",
    "        clean = clean.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        enhanced = model(degraded)\n",
    "        loss = criterion(enhanced, clean)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate metrics\n",
    "        psnr_val, ssim_val = calculate_metrics(enhanced, clean)\n",
    "        \n",
    "        # Update running metrics\n",
    "        running_loss += loss.item()\n",
    "        running_psnr += psnr_val\n",
    "        running_ssim += ssim_val\n",
    "        \n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({\n",
    "            'loss': f'{loss.item():.4f}',\n",
    "            'psnr': f'{psnr_val:.2f}',\n",
    "            'ssim': f'{ssim_val:.4f}'\n",
    "        })\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_psnr = running_psnr / len(dataloader)\n",
    "    epoch_ssim = running_ssim / len(dataloader)\n",
    "    \n",
    "    return epoch_loss, epoch_psnr, epoch_ssim\n",
    "\n",
    "\n",
    "def validate_epoch(model, dataloader, criterion, device):\n",
    "    \"\"\"Validate for one epoch\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_psnr = 0.0\n",
    "    running_ssim = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(dataloader, desc='Validation')\n",
    "        for degraded, clean in progress_bar:\n",
    "            degraded = degraded.to(device)\n",
    "            clean = clean.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            enhanced = model(degraded)\n",
    "            loss = criterion(enhanced, clean)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            psnr_val, ssim_val = calculate_metrics(enhanced, clean)\n",
    "            \n",
    "            # Update running metrics\n",
    "            running_loss += loss.item()\n",
    "            running_psnr += psnr_val\n",
    "            running_ssim += ssim_val\n",
    "            \n",
    "            # Update progress bar\n",
    "            progress_bar.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "                'psnr': f'{psnr_val:.2f}',\n",
    "                'ssim': f'{ssim_val:.4f}'\n",
    "            })\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_psnr = running_psnr / len(dataloader)\n",
    "    epoch_ssim = running_ssim / len(dataloader)\n",
    "    \n",
    "    return epoch_loss, epoch_psnr, epoch_ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57426679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_psnr': [],\n",
    "    'train_ssim': [],\n",
    "    'val_loss': [],\n",
    "    'val_psnr': [],\n",
    "    'val_ssim': []\n",
    "}\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_model_path = model_dir / 'best_unet_model.pth'\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STARTING TRAINING\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{EPOCHS}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_psnr, train_ssim = train_epoch(\n",
    "        model, train_loader, criterion, optimizer, DEVICE\n",
    "    )\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_psnr, val_ssim = validate_epoch(\n",
    "        model, val_loader, criterion, DEVICE\n",
    "    )\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # Save history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_psnr'].append(train_psnr)\n",
    "    history['train_ssim'].append(train_ssim)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_psnr'].append(val_psnr)\n",
    "    history['val_ssim'].append(val_ssim)\n",
    "    \n",
    "    # Print epoch summary\n",
    "    print(f\"\\nEpoch {epoch + 1} Summary:\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f} | PSNR: {train_psnr:.2f} dB | SSIM: {train_ssim:.4f}\")\n",
    "    print(f\"  Val Loss:   {val_loss:.4f} | PSNR: {val_psnr:.2f} dB | SSIM: {val_ssim:.4f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': val_loss,\n",
    "            'val_psnr': val_psnr,\n",
    "            'val_ssim': val_ssim,\n",
    "        }, best_model_path)\n",
    "        print(f\"  ✓ Best model saved! (Val Loss: {val_loss:.4f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING COMPLETE!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84c392b",
   "metadata": {},
   "source": [
    "## 8. Visualize Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66998919",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "fig.suptitle('Training Progress', fontsize=16, fontweight='bold')\n",
    "\n",
    "epochs_range = range(1, len(history['train_loss']) + 1)\n",
    "\n",
    "# Loss plot\n",
    "axes[0].plot(epochs_range, history['train_loss'], 'b-', label='Train Loss', linewidth=2)\n",
    "axes[0].plot(epochs_range, history['val_loss'], 'r-', label='Val Loss', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0].set_title('Loss Curve', fontsize=14)\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# PSNR plot\n",
    "axes[1].plot(epochs_range, history['train_psnr'], 'b-', label='Train PSNR', linewidth=2)\n",
    "axes[1].plot(epochs_range, history['val_psnr'], 'r-', label='Val PSNR', linewidth=2)\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('PSNR (dB)', fontsize=12)\n",
    "axes[1].set_title('PSNR Progress', fontsize=14)\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# SSIM plot\n",
    "axes[2].plot(epochs_range, history['train_ssim'], 'b-', label='Train SSIM', linewidth=2)\n",
    "axes[2].plot(epochs_range, history['val_ssim'], 'r-', label='Val SSIM', linewidth=2)\n",
    "axes[2].set_xlabel('Epoch', fontsize=12)\n",
    "axes[2].set_ylabel('SSIM', fontsize=12)\n",
    "axes[2].set_title('SSIM Progress', fontsize=14)\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(model_dir / 'training_curves.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Training curves saved to: {model_dir / 'training_curves.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a48640",
   "metadata": {},
   "source": [
    "## 9. Test Model on Validation Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f32202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "checkpoint = torch.load(best_model_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "print(f\"Loaded best model from epoch {checkpoint['epoch'] + 1}\")\n",
    "print(f\"  Val Loss: {checkpoint['val_loss']:.4f}\")\n",
    "print(f\"  Val PSNR: {checkpoint['val_psnr']:.2f} dB\")\n",
    "print(f\"  Val SSIM: {checkpoint['val_ssim']:.4f}\")\n",
    "\n",
    "# Get sample batch\n",
    "degraded, clean = next(iter(val_loader))\n",
    "degraded = degraded.to(DEVICE)\n",
    "clean = clean.to(DEVICE)\n",
    "\n",
    "# Generate predictions\n",
    "with torch.no_grad():\n",
    "    enhanced = model(degraded)\n",
    "\n",
    "# Visualize results\n",
    "fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
    "fig.suptitle('Model Predictions - Validation Set', fontsize=16, fontweight='bold')\n",
    "\n",
    "for i in range(4):\n",
    "    # Degraded image\n",
    "    axes[0, i].imshow(degraded[i, 0].cpu().numpy(), cmap='gray')\n",
    "    axes[0, i].set_title(f'Degraded {i+1}', fontsize=12)\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # Enhanced image\n",
    "    axes[1, i].imshow(enhanced[i, 0].cpu().numpy(), cmap='gray')\n",
    "    psnr_val, ssim_val = calculate_metrics(enhanced[i:i+1], clean[i:i+1])\n",
    "    axes[1, i].set_title(f'Enhanced {i+1}\\nPSNR: {psnr_val:.2f} dB', fontsize=12)\n",
    "    axes[1, i].axis('off')\n",
    "    \n",
    "    # Ground truth\n",
    "    axes[2, i].imshow(clean[i, 0].cpu().numpy(), cmap='gray')\n",
    "    axes[2, i].set_title(f'Ground Truth {i+1}\\nSSIM: {ssim_val:.4f}', fontsize=12)\n",
    "    axes[2, i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(model_dir / 'validation_results.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Validation results saved to: {model_dir / 'validation_results.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b78434",
   "metadata": {},
   "source": [
    "## 10. Save Training Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363808bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training history\n",
    "with open(model_dir / 'training_history.json', 'w') as f:\n",
    "    json.dump(history, f, indent=2)\n",
    "\n",
    "# Save model metadata\n",
    "metadata = {\n",
    "    'model_architecture': 'U-Net',\n",
    "    'input_channels': 1,\n",
    "    'output_channels': 1,\n",
    "    'image_size': 256,\n",
    "    'total_parameters': sum(p.numel() for p in model.parameters()),\n",
    "    'training': {\n",
    "        'epochs': EPOCHS,\n",
    "        'learning_rate': LEARNING_RATE,\n",
    "        'batch_size': 8,\n",
    "        'optimizer': 'Adam',\n",
    "        'loss_function': 'Combined L1 + MSE',\n",
    "        'train_samples': len(train_dataset),\n",
    "        'val_samples': len(val_dataset)\n",
    "    },\n",
    "    'best_results': {\n",
    "        'epoch': checkpoint['epoch'] + 1,\n",
    "        'val_loss': float(checkpoint['val_loss']),\n",
    "        'val_psnr': float(checkpoint['val_psnr']),\n",
    "        'val_ssim': float(checkpoint['val_ssim'])\n",
    "    },\n",
    "    'timestamp': datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "with open(model_dir / 'model_metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL ARTIFACTS SAVED\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nModel directory: {model_dir}\")\n",
    "print(f\"\\nFiles saved:\")\n",
    "print(f\"  ✓ best_unet_model.pth - Trained model weights\")\n",
    "print(f\"  ✓ training_history.json - Training metrics\")\n",
    "print(f\"  ✓ model_metadata.json - Model configuration\")\n",
    "print(f\"  ✓ training_curves.png - Training visualization\")\n",
    "print(f\"  ✓ validation_results.png - Validation samples\")\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff988844",
   "metadata": {},
   "source": [
    "## 11. Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020a5c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL MODEL SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nArchitecture: U-Net for Medical Image Enhancement\")\n",
    "print(f\"Total Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"\\nTraining Configuration:\")\n",
    "print(f\"  Epochs: {EPOCHS}\")\n",
    "print(f\"  Initial Learning Rate: {LEARNING_RATE}\")\n",
    "print(f\"  Batch Size: 8\")\n",
    "print(f\"  Loss Function: Combined L1 (70%) + MSE (30%)\")\n",
    "print(f\"\\nBest Model Performance:\")\n",
    "print(f\"  Validation Loss: {checkpoint['val_loss']:.4f}\")\n",
    "print(f\"  Validation PSNR: {checkpoint['val_psnr']:.2f} dB\")\n",
    "print(f\"  Validation SSIM: {checkpoint['val_ssim']:.4f}\")\n",
    "print(f\"  Saved at Epoch: {checkpoint['epoch'] + 1}\")\n",
    "print(f\"\\nModel saved to: {best_model_path}\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"✓ Training notebook completed successfully!\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
